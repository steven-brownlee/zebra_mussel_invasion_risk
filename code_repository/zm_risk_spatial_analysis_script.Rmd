
# Spatial analysis script, invasion risk

# Contact information

Contact: Steven Brownlee
Email: steven.fr.brownlee@gmail.com
Date last revised: June 24 2024

# Session info

R version 4.4.1 (2024-06-14)
Platform: x86_64-redhat-linux-gnu
Running under: Nobara Linux 40 (GNOME Edition)

Matrix products: default
BLAS/LAPACK: FlexiBLAS OPENBLAS-OPENMP;  LAPACK version 3.11.0

locale:
 [1] LC_CTYPE=en_CA.UTF-8      LC_NUMERIC=C              LC_TIME=en_CA.utf8       
 [4] LC_COLLATE=en_CA.UTF-8    LC_MONETARY=en_CA.utf8    LC_MESSAGES=en_CA.UTF-8  
 [7] LC_PAPER=en_CA.utf8       LC_NAME=C                 LC_ADDRESS=C             
[10] LC_TELEPHONE=C            LC_MEASUREMENT=en_CA.utf8 LC_IDENTIFICATION=C      

time zone: America/Vancouver
tzcode source: system (glibc)

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] digest_0.6.36     tidyr_1.3.1       utf8_1.2.4        R6_2.5.1         
 [5] fastmap_1.2.0     tidyselect_1.2.1  xfun_0.46         magrittr_2.0.3   
 [9] glue_1.7.0        tibble_3.2.1      knitr_1.48        pkgconfig_2.0.3  
[13] htmltools_0.5.8.1 rmarkdown_2.27    dplyr_1.1.4       generics_0.1.3   
[17] lifecycle_1.0.4   cli_3.6.3         fansi_1.0.6       vctrs_0.6.5      
[21] compiler_4.4.1    purrr_1.0.2       rstudioapi_0.16.0 tools_4.4.1      
[25] pillar_1.9.0      evaluate_0.24.0   yaml_2.3.10       rlang_1.1.4   

# Set up data directory

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = '/home/steven/Documents/workspace/thesis/ch1/gis_data/')
```

# R library setup

```{r}
library(sf)
library(tidyverse)
library(rcartocolor)
library(sfnetworks)
library(qgisprocess)
library(future)
library(future.callr)
library(purrr)
library(furrr)
library(progressr)
library(stars)
library(paletteer)
library(ggnewscale)
library(terra)
library(tidyterra)
library(nngeo)
library(imputeTS)
```

# Set up Python

```{r Python setup}

install.packages("reticulate")

library(reticulate)

install_miniconda(path = miniconda_path(), update = T)

reticulate::install_python()

reticulate::virtualenv_create(envname = 'cci_lakes')

use_virtualenv('cci_lakes')

reticulate::py_install(packages = c('xarray', 'dask', 'netCDF4', 'bottleneck', 
                                    'rasterio', 'pyproj', 'geopandas', 'pandas', 
                                    'cartopy', 'distributed', 'numpy',
                                    'datetime'))

```

# Import common files, process

```{r}


bc_bbox <- vect('auxiliary_files/bc_bbox.gpkg')

na_bbox <- vect('auxiliary_files/north_america_cci_bbox.gpkg') %>% 
  project('EPSG:4326')

cci_lakes_name_corrected <- read_sf('auxiliary_files/cci_lakes_corrected.gpkg') 

```

## Processing for above

```{r}
wwf_glwd_1 <- read_sf('downloads/WWF_GLWD_level1/glwd_1.shp') %>% 
  st_set_crs(4326) %>% 
  select(LAKE_NAME) %>% 
  st_make_valid()

cci_lakes_joined <- st_join(cci_lakes_outline_sf, wwf_glwd_1)

cci_lakes_name_corrected <- cci_lakes_joined %>%
  mutate(name = coalesce(name, LAKE_NAME)) %>% 
  select(name, id) %>% 
  st_transform(crs = 4087) %>% 
  st_buffer(dist = 400) %>% 
  mutate(identity = 1)

write_sf(cci_lakes_name_corrected, 'auxiliary_files/cci_lakes_corrected.gpkg')

```



# 1.) Download files from CCI database.


```{r}

path = 'cci_lakes_download/'

###

prefix_template <- 'https://dap.ceda.ac.uk/neodc/esacci/lakes/data/lake_products/L3S/v2.1/merged_product/'

suffix_template_a <- 'ESACCI-LAKES-L3S-LK_PRODUCTS-MERGED-'

suffix_template_b <- '-fv2.1.0.nc'

###

year_list <- c('2016', '2017', '2018', '2019', '2020')

month_list <- c('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')

month_daylengths <- c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)

day_list <- c( '01',  '02',  '03',  '04',  '05',  '06',  '07',  '08',  '09', 
               '10', '11', '12', '13',  '14', '15', '16', '17', '18', '19', 
               '20',  '21', '22', '23', '24', '25', '26', '27', '28', '29', 
               '30', '31')

comb_date <- paste0(year_list[1], month_list[1], day_list[1])

date_dir <- paste0(year_list[1], '/', month_list[1], '/')

for (i in 1:5) {
  ival <- eval(i)
  
  interior_year <- year_list[ival]
  
  for (j in 1:12) {
    jval <- eval(j)
    
    interior_month <- month_list[jval]
    
    interior_day_length <- month_daylengths[jval]
    
    if (interior_month == '02' & interior_year == '2016') {
      interior_day_length <- 29
      print('Leap year!')
    } 
    
    if (interior_month == '02' & interior_year == '2020') {
      interior_day_length <- 29
      print('Leap year!')
    }

    for (k in 1:interior_day_length) {
      kval <- eval(k)
      
      interior_day <- day_list[kval]
      
      comb_date <- paste0(interior_year,  interior_month, interior_day )
      
      date_dir <- paste0(interior_year, '/', interior_month , '/')
      
      filename <- paste0(prefix_template, date_dir, suffix_template_a, comb_date,
                              suffix_template_b)

      download.file(filename, paste0(path, basename(filename)))
      
      print(paste('Completed:', filename))
      
    }
    
  }
  
}

```

# 2.) Process .nc files and export as RDS

## 2a.) Create assembly frame

```{r}


cci_files <- list.files('cci_lakes_download', 
                            pattern = '*.nc',
                            full.names = TRUE,
                            recursive = TRUE)

###

# Assembly scaffold

coord_data_table <- tibble(uid = numeric(),
                           x = numeric(),
                      y = numeric(),
                      x_wgs = numeric(),
                      y_wgs = numeric(),
                      name = character(),
                      id = numeric())


input_file <- cci_files[1]

coord_frame <- rast(input_file) %>% 
    select(lake_surface_water_temperature) %>% 
    crop(na_bbox) %>%
    st_as_stars() %>% 
    as_tibble() %>% 
    select(x, y) %>% 
   rowid_to_column('uid')

coord_frame$clipping_group <- as.numeric(cut_number(coord_frame$uid, 2000))


for (i in 1500:2000) {
  ival = eval(i)
    
  split <- coord_frame %>% 
    filter(clipping_group == ival)
  
  split_sf <- split %>% 
      st_as_sf(coords = c('x', 'y'),
                 crs = 4326) %>% 
            mutate(x_wgs = sf::st_coordinates(.)[,1],
               y_wgs = sf::st_coordinates(.)[,2]) %>% 
      st_transform(4087) %>% 
      st_intersection(cci_lakes_name_corrected)
  
  if (nrow(split_sf) > 0) {
      split_tibble <- split_sf %>% 
        mutate(x = sf::st_coordinates(.)[,1],
               y = sf::st_coordinates(.)[,2]) %>% 
        st_drop_geometry()
      
        coord_data_table <- bind_rows(coord_data_table, split_tibble)
        
        print(paste('Completed:', ival, 'of', 2000))
    } else {
        print(paste('No data for', ival, 'of', 2000))
      }
      
      }

###

assembly_frame_list <- list.files('cci_assembly_frame/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

assembly_frame_sf <- lapply(assembly_frame_list, readRDS) %>% 
  bind_rows() %>% 
  st_as_sf(coords = c('x', 'y'),
           crs = 4087) %>% 
  select(-uid, -clipping_group)
  
assembly_frame_rds <- lapply(assembly_frame_list, readRDS) %>% 
  bind_rows() %>% 
    select(-uid, -clipping_group)

write_rds(assembly_frame_rds, 'cci_assembly_frame/cci_assembly_frame_complete.rds')

write_sf(assembly_frame_sf, 'cci_assembly_frame/cci_assembly_frame_sf.gpkg')

```

## 2b.) Attach files to assembly frame, export

```{r}

assembly_frame_sf <- read_sf('cci_assembly_frame/cci_assembly_frame_sf.gpkg')

assembly_frame_rds <- readRDS('cci_assembly_frame/cci_assembly_frame_complete.rds')


###


cci_files <- list.files('cci_lakes_download', 
                            pattern = '*.nc',
                            full.names = TRUE,
                            recursive = TRUE)

outdir <- 'cci_lakes_rds/'


for (i in 5205:6940) {
  ival <- eval(i)
  input_file <- cci_files[ival]
  input_filename <- basename(input_file)
  
  ## Extract dates from filename, check if already exists
  
  year_extract <- substr(input_filename, 37, 40)
  month_extract <- substr(input_filename, 41, 42)
  date_extract <- substr(input_filename, 43, 44)
  composite_date <- paste0(date_extract, '-', month_extract, '-', year_extract)
 
  output_filename <- paste0(outdir, 'cci_lakes_', composite_date, '_processed.rds')
  
  if(file.exists(output_filename) == TRUE) {
    
    print(paste('File already generated for', ival, 'of', length(cci_files), 'skipping!'))
    
  } else {
    
  ## Extract data from file
  
  interior_terra <- rast(input_file)
  
  t_chla_mean <- interior_terra %>% 
  select(chla_mean) %>% 
  crop(na_bbox) %>% 
  st_as_stars()
  
  ##
  
  t_chla_uncertainty <- interior_terra %>% 
  select(chla_uncertainty) %>% 
  crop(na_bbox) %>% 
  st_as_stars() 
  
  ##
  
  t_lake_surface_water_temperature <- interior_terra %>% 
  select(lake_surface_water_temperature) %>% 
  crop(na_bbox) %>% 
  st_as_stars() %>% 
    rename(lswt = lake_surface_water_temperature)

  
  ##
  
  t_lswt_uncertainty <- interior_terra %>% 
   select(lswt_uncertainty) %>% 
  crop(na_bbox) %>% 
  st_as_stars()
  
  ##
 
  t_lswt_quality_level <- interior_terra %>% 
   select(lswt_quality_level) %>% 
  crop(na_bbox) %>% 
  st_as_stars() 
  
  ##
  
  t_turbidity_mean <- interior_terra %>% 
   select(turbidity_mean) %>% 
  crop(na_bbox) %>% 
  st_as_stars() 
  
  ##
  
  t_turbidity_uncertainty <- interior_terra %>% 
   select(turbidity_uncertainty) %>% 
  crop(na_bbox) %>% 
  st_as_stars()
  
  ##
  
  t_rw_443 <- interior_terra %>% 
   select(Rw443) %>% 
  crop(na_bbox) %>% 
  st_as_stars() %>% 
  rename(rw_443 = Rw443)
  
  ###
  
  t_rw_443_u <- interior_terra %>% 
   select(Rw443_uncertainty_relative) %>% 
  crop(na_bbox) %>% 
  st_as_stars() %>% 
  rename(rw_443_u = Rw443_uncertainty_relative)

  ###
  
   t_rw_560 <- interior_terra %>% 
   select(Rw560) %>% 
  crop(na_bbox) %>% 
  st_as_stars() %>% 
  rename(rw_560 = Rw560)
  
  ###
    
   
   t_rw_560_u <- interior_terra %>% 
   select(Rw560_uncertainty_relative) %>% 
  crop(na_bbox) %>% 
  st_as_stars() %>% 
  rename(rw_560_u = Rw560_uncertainty_relative)
   
   ### 
  
  combined <- c(t_chla_mean, t_chla_uncertainty, 
                        t_lake_surface_water_temperature, t_lswt_uncertainty, 
                        t_lswt_quality_level, t_turbidity_mean, t_turbidity_uncertainty,
                        t_rw_443, t_rw_443_u, t_rw_560, t_rw_560_u) %>% 
    as_tibble() %>% 
    mutate(date = composite_date)
  
  combined_filtered <- left_join(assembly_frame_rds, combined, 
                               by = c('x_wgs' = 'x', 
                                      'y_wgs' = 'y'))

  # Prep for export 
  
  write_rds(combined_filtered, output_filename)
  
  print(paste('Completed:', ival, 'of', length(cci_files)))
  
    rm(interior_terra, combined, combined_filtered, t_chla_mean, t_chla_uncertainty, 
                        t_lake_surface_water_temperature, t_lswt_uncertainty, 
                        t_lswt_quality_level, t_turbidity_mean, t_turbidity_uncertainty,
                        t_rw_443, t_rw_443_u, t_rw_560, t_rw_560_u )
    
    gc()
  }
  
  
  gc()
}
  

```


# 3.) Read .rds files, process into stars objects

# 4.) Fill time series gaps

## Aggregate to one-week intervals

```{r}


cci_rds <- list.files('/run/media/steven/data_storage/cci_lakes_rds/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

leftover_path <- '/mnt/33ac07c2-b4a0-4614-8506-d06fb974ca86/florilegium_leftover/'

cci_rds_2 <- list.files(leftover_path, 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

cci_combined <- c(cci_rds, cci_rds_2)


year_list <- c('2002', '2003', '2004', '2005', '2006', '2007', 
               '2008', '2009', '2010', '2011', '2012', '2013', 
               '2014', '2015', '2016', '2017', '2018', '2019',
               '2020') %>% 
  as_tibble() %>% 
  rename(year = value) %>% 
  rowid_to_column('year_id')

month_list <- c('01', '02', '03', '04', '05', '06', 
                '07', '08', '09', '10', '11', '12') %>% 
  as_tibble() %>% 
  rename(month = value) %>% 
  rowid_to_column('month_id')

### Year by year version


for (i in 1:nrow(year_list)) {
    ival = eval(i)
    year_interior <- year_list %>% filter(year_id == ival)
    year_subset <- str_subset(cci_combined, 
                                pattern = year_interior$year)
    
    for (j in 1:nrow(month_list)) {
      jval = eval(j)
      month_interior <- month_list %>% filter(month_id == jval)
      month_subset <- str_subset(year_subset, 
                                pattern = paste0('-', month_interior$month, '-'))
      
      filename <- paste0('cci_lakes_weekly/cci_lakes_', 
                         month_interior$month, '_',
                         year_interior$year, '.rds')
      
      if (file.exists(filename) == FALSE) {
        
         month_data <- lapply(month_subset, readRDS) %>% 
           bind_rows()
         
         month_data$date <- dmy(month_data$date)
         
         month_data$week <- floor_date(month_data$date, "week")
         
         month_data_summarized <- month_data %>%     
           group_by(x, y, week) %>%
           summarize(chla_mean = mean(chla_mean),
              lswt = mean(lswt),
              lswt_uncertainty = mean(lswt_uncertainty),
              lswt_quality_level = max(lswt_quality_level),
              turbidity_mean = mean(turbidity_mean),
              turbidity_uncertainty = max(turbidity_uncertainty),
              rw_443 = mean(rw_443),
              rw_443_u = mean(rw_443_u),
              rw_560 = mean(rw_560),
              rw_560_u = mean(rw_560_u))
         
         write_rds(month_data_summarized, filename)
         
         print(paste('Completed:', month_interior$month, 'of', year_interior$year))
         
         rm(month_data, month_data_summarized)
         
         gc()
        
      } else {
        
        print(paste(month_interior$month, 'of', year_interior$year, 'file already exists - skipping!'))
        
      }
    }
      print(paste('~~~ Completed:', year_interior$year))
}


```

## Subset data

```{r}
# Import assembly frame

assembly_frame <- read_sf('cci_assembly_frame/cci_assembly_frame_sf.gpkg')

### Generate BC subset CCI data

cci_lakes_shapefile <- read_sf('auxiliary_files/cci_lakes_shapefile.gpkg') %>% 
  st_transform(st_crs(4087))

bc_bbox <- read_sf('auxiliary_files/bc_bbox.gpkg') %>% 
  st_transform(st_crs(4087))

cci_lakes_bc <- st_intersection(cci_lakes_shapefile, bc_bbox) %>% 
  select(id, name) %>% 
  mutate(area = st_area(geom))

cci_lakes_bc$area <- as.numeric(cci_lakes_bc$area)

cci_lakes_bc <- cci_lakes_bc %>% 
  mutate(area_km = area/1000000)

## North America

na_bbox <- read_sf('auxiliary_files/north_america_bbox.gpkg') %>% 
  st_transform(st_crs(4087))

cci_lakes_north_america <- st_intersection(cci_lakes_shapefile, na_bbox)%>% 
  select(id, name) 

### import Guerin et al 2024 data

calcium_data <- read_csv('downloads/guerin_et_al_2024_data/dryad/site-date_calcium_985955.csv') %>% 
  st_as_sf(coords = c('LONGITUDE', 'LATITUDE'),
           crs = 4326) %>% 
  st_transform(crs = 4087) %>% 
        mutate(x = sf::st_coordinates(.)[,1],
                y = sf::st_coordinates(.)[,2])

calcium_coords <- calcium_data %>% 
    st_drop_geometry() %>% 
  select(x, y) %>% 
  distinct(x, y) %>% 
  rowid_to_column('calcium_coord_id')

calcium_data_tagged <- left_join(calcium_data, 
                                 calcium_coords, 
                                 by = c('x', 'y'))

calcium_coords <- calcium_coords %>% 
  st_as_sf(crs = 4087, 
           coords = c('x', 'y')) %>% 
  st_set_crs(4087)



cci_lakes_calcium_match <- st_join(cci_lakes_north_america, calcium_coords) %>% 
  drop_na() %>% 
  group_by(id) %>% 
  summarize()

assembly_frame_calcium_subset <- st_intersection(assembly_frame, cci_lakes_calcium_match) %>% 
  mutate(x = sf::st_coordinates(.)[,1],
         y = sf::st_coordinates(.)[,2]) %>% 
  st_drop_geometry() %>% 
  select(x, y)

write_rds(assembly_frame_calcium_subset,'cci_assembly_frame/assembly_frame_calcium_subset.rds')


assembly_frame_bc_subset <- st_intersection(assembly_frame, cci_lakes_bc) %>% 
    mutate(x = sf::st_coordinates(.)[,1],
         y = sf::st_coordinates(.)[,2]) %>% 
  select(x, y) %>% 
  st_drop_geometry()

write_rds(assembly_frame_bc_subset,'cci_assembly_frame/assembly_frame_bc_subset.rds')

# ~~~

assembly_frame_calcium_subset <- readRDS('cci_assembly_frame/assembly_frame_calcium_subset.rds') %>% 
  rowid_to_column('frame_id') 

assembly_frame_bc_subset <- readRDS('cci_assembly_frame/assembly_frame_bc_subset.rds') %>% 
  rowid_to_column('frame_id')

# ~~~

date_assembler <- function(frame_sequence, date_frame, assembly_frame) {
  
  product_frame <- tibble(x = numeric(),
                          y = numeric(),
                          frame_id = numeric())
  
  for (i in sequence) {
    ival = eval(i)
    date_interior <- date_frame %>% mutate(frame_id = ival)
    assembly_frame_interior <- left_join(assembly_frame,
                                                 date_interior, 
                                                 by = 'frame_id') %>% 
      drop_na()
    product_frame <- bind_rows(product_frame,  assembly_frame_calcium_interior)
  }
  return(product_frame)
}

# ~~~

cci_weekly_rds <- list.files('cci_lakes_weekly/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

cci_bc_path <- 'cci_bc_data/'

cci_calcium_path <- 'cci_calcium_data/'

plan(callr, workers = 12)
options(future.globals.maxSize = 1.6e+10)

for (i in 1:length(cci_weekly_rds)) {
  ival <- eval(i)
  calcium_filename <- paste0(cci_calcium_path, 'calcium_', basename(cci_weekly_rds[ival]))
  cci_weekly_interior <- readRDS(cci_weekly_rds[ival])
  dates <- as_tibble(unique(cci_weekly_interior$week)) %>% 
    rename(week = value)
  assembly_frame_calc_int <- assembly_frame_calcium_subset
  
  assembly_frame_date_attached <- 
    future_map(1:nrow(assembly_frame_calc_int), 
               ~date_assembler(.x, 
                               date_frame = dates,
                               assembly_frame = assembly_frame_calc_int)) %>% 
    bind_rows()
  data_filtered <- left_join(assembly_frame_date_attached,
                             cci_weekly_interior,
                             by = c('x', 'y', 'week'))
  write_rds(data_filtered, calcium_filename)
  
  print(paste('Completed:', ival, 'of', length(cci_weekly_rds)))
  

  }
  

for (i in 1:length(cci_weekly_rds)) {
  ival <- eval(i)
  bc_filename <- paste0(cci_bc_path, 'bc_', basename(cci_weekly_rds[ival]))
  cci_weekly_interior <- readRDS(cci_weekly_rds[ival])
  dates <- as_tibble(unique(cci_weekly_interior$week)) %>% 
    rename(week = value)
  assembly_frame_bc_int <- assembly_frame_bc_subset
  
  assembly_frame_date_attached <- 
    future_map(1:nrow(assembly_frame_bc_int), 
               ~date_assembler(.x, 
                               date_frame = dates,
                               assembly_frame = assembly_frame_bcd_int)) %>% 
    bind_rows()
  data_filtered <- left_join(assembly_frame_date_attached,
                             cci_weekly_interior,
                             by = c('x', 'y', 'week'))
  write_rds(data_filtered, bc_filename)
  
  print(paste('Completed:', ival, 'of', length(cci_weekly_rds)))
  

  }
  
  
  
  cci_weekly_interior$week <- as.character(cci_weekly_interior$week)
  
  
    
  
    
    
}

```



## K-nearest neighbour


```{r}

# First pass, using k-nearest neighbour filling


nn_filler <- function(rds_interior) {
  
  outer_template <- tibble(x = numeric(),
                         y = numeric(),
                         point_id = numeric(),
                         week = date(),
                         chla_mean = numeric(),
                         chla_uncertainty = numeric(),
                         lswt = numeric(),
                         lswt_uncertainty = numeric(),
                         lswt_quality_level = numeric(),
                         turbidity_mean = numeric(),
                         turbidity_uncertainty = numeric(),
                         rw_443 = numeric(),
                         rw_443_u = numeric(),
                         rw_560 = numeric(),
                         rw_560_u = numeric(),
                         group_id = numeric(),
                         name = character(),
                         id = numeric())
  
  outer_template$week <- as.Date(outer_template$week)
  
    date_sequence <- rds_interior %>% 
      ungroup() %>% 
      select(week) %>% 
      distinct(week) %>% 
      arrange(week) %>% 
      deframe()
    
    for (i in 1:length(date_sequence)) {
      ival = eval(i)
      date_selection <- date_sequence[ival]
      rds_filtered <- rds_interior %>% 
        filter(week == date_selection) %>% 
        group_by(x, y) %>% 
        mutate(point_id = cur_group_id()) %>% 
        ungroup()
      
      point_id_filtered <- unique(rds_filtered$point_id)
      point_id_length <- length(point_id_filtered)
      
          for (j in 1:eval(point_id_length)) {
            jval <- eval(j)
            rds_point_data <- rds_filtered %>% 
              filter(point_id == point_id_filtered[j])
            rds_point <- rds_filtered %>% 
              filter(point_id == point_id_filtered[j]) %>% 
              st_as_sf(coords = c('x', 'y'),
               crs = 4087) %>% 
              select(geometry)
            
            rds_comparison <- rds_filtered %>% 
              filter(point_id != point_id_filtered[j]) %>% 
              st_as_sf(coords = c('x', 'y'),
                       crs = 4087)
            
            rds_nn <- suppressWarnings(suppressMessages(st_join(rds_point, 
                                                        rds_comparison, 
                                                        st_is_within_distance, 
                                                        dist = 2000))) %>% 
              mutate(grouping_id = 1)
            
            rds_nn_summ <- rds_nn %>% 
              group_by(grouping_id) %>% 
              summarize(chla_mean = mean(chla_mean),
                lswt_mean = mean(lswt),
                turbidity_mean = mean(turbidity_mean),
                rw_443_mean = mean(rw_443),
                rw_560_mean = mean(rw_560)) %>% 
              st_drop_geometry()
            
            eval_criteria <- rds_point_data %>% 
              select(x, y, point_id, chla_mean, lswt, turbidity_mean,
               rw_443, rw_560) 
            
            if (is.na(eval_criteria$chla_mean) == TRUE) {
              rds_point_data$chla_mean <- rds_nn_summ$chla_mean
        }
            if (is.na(eval_criteria$lswt) == TRUE) {
              rds_point_data$lswt <- rds_nn_summ$lswt_mean
        }
            if (is.na(eval_criteria$turbidity_mean) == TRUE) {
              rds_point_data$turbidity_mean <- rds_nn_summ$turbidity_mean
      }
            if (is.na(eval_criteria$rw_443) == TRUE) {
              rds_point_data$rw_443 <- rds_nn_summ$rw_443_mean
      }
            if (is.na(eval_criteria$rw_560) == TRUE) {
              rds_point_data$rw_560 <- rds_nn_summ$rw_560_mean
      }
      
          outer_template <- bind_rows(outer_template, rds_point_data)

    }
      
    }
    
  
   return(outer_template)
}

###

cci_l_l <- list.files('cci_lakes_weekly/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

### 


for (i in 1:length(cci_l_l)) {
  ival = eval(i)
  lake_rds <- read_rds(cci_l_l[ival])
  filename <- paste0('cci_knn/', basename(cci_l_l[ival]))
  
  lake_filled_knn <- future_map(nn_filler(rds_interior = lake_rds)) %>% 
    bind_rows()
  
  write_rds(lake_filled_knn, filename)
  print(paste('Completed:', cci_l_l[ival]))
  
}


# Advesperascit

plan(callr, workers = 12)
options(future.globals.maxSize = 1.6e+10)

for (i in 1:10) {
  ival = eval(i)
  lake_rds <- read_rds(cci_l_l[ival]) %>% 
    rename(date = week)
  filename <- paste0('cci_knn/', basename(cci_l_l[ival]))
  
  lake_filled_knn <- future_map(1:1827,
                          ~nn_filler(.x, rds_interior = lake_rds)) %>% 
    bind_rows()
  
  write_rds(lake_filled_knn, filename)
  print(paste('Completed:', cci_l_l[ival]))
  
}
  
# Revacholiere

plan(callr, workers = 12)
options(future.globals.maxSize = 1.6e+10)

for (i in 10:20) {
  ival = eval(i)
  lake_rds <- read_rds(cci_l_l[ival]) %>% 
    rename(date = week)
  filename <- paste0('cci_knn/', basename(cci_l_l[ival]))
  lake_filled_knn <- future_map(1:1827,
                          ~nn_filler(.x, rds_interior = lake_rds)) %>% 
    bind_rows()
  
  write_rds(lake_filled_knn, filename)
  print(paste('Completed:', cci_l_l[ival]))
  
}

# Florilegium

plan(callr, workers = 10)
options(future.globals.maxSize = 1.6e+10)

for (i in 20:30) {
  ival = eval(i)
  lake_rds <- read_rds(cci_l_l[ival]) %>% 
    rename(date = week)
  filename <- paste0('cci_knn/', basename(cci_l_l[ival]))
  
  lake_filled_knn <- future_map(1:1827,
                          ~nn_filler(.x, rds_interior = lake_rds)) %>% 
    bind_rows()
  
  write_rds(lake_filled_knn, filename)
  print(paste('Completed:', cci_l_l[ival]))
  
}

# Cognoscere

plan(callr, workers = 15)
options(future.globals.maxSize = 1.6e+10)

for (i in 30:40) {
  ival = eval(i)
  lake_rds <- read_rds(cci_l_l[ival]) %>% 
    rename(date = week)
  lake_rds <- lake_rds %>% distinct(point_id, date, .keep_all = TRUE)
  filename <- paste0('cci_knn/', basename(cci_l_l[ival]))
  
  lake_filled_knn <- future_map(1:1827,
                          ~nn_filler(.x, rds_interior = lake_rds)) %>% 
    bind_rows()
  
  write_rds(lake_filled_knn, filename)
  print(paste('Completed:', cci_l_l[ival]))
  
}

# Second pass, using imputeTS


cci_knn <- list.files('cci_knn/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)


for (i in 1:length(cci_knn)) {
  ###
  
  ival <- eval(i)
  
  int_slice <- readRDS(cci_knn[ival]) %>% 
    rename(lswt = lwst)
  
  ##
  
  int_slice_points <- unique(int_slice$point_id)
  
  int_slice_length <- length(int_slice_points)
  
  ##

  chla <- int_slice %>% 
    select(x, y, point_id, date, chla_mean)
  
  temp <- int_slice %>% 
    select(x, y, point_id, date, lswt)
  
  turb <- int_slice %>% 
    select(x, y, point_id, point_id, date, turbidity_mean)
  
  rw_443 <- int_slice %>% 
    select(x, y, point_id, point_id, date, rw_443)
  
  rw_560 <- int_slice %>% 
    select(x, y, point_id, point_id, date, rw_560)
  
  
  date_frame <- int_slice %>% 
    select(-chla_mean, -lswt, -turbidity_mean,
           -rw_443, -rw_560)
  
  ##
  
  chla <- chla %>% 
    group_by(x, y) %>% 
    group_modify(~ as.data.frame(na_interpolation(.x)),
                 option = 'stine')
  
  temp <- temp %>% 
    group_by(x, y) %>% 
    group_modify(~ as.data.frame(na_interpolation(.x)),
                 option = 'stine') 
  
  turb <- turb %>% 
    group_by(x, y) %>% 
    group_modify(~ as.data.frame(na_interpolation(.x)),
                 option = 'stine')
  
  rw_443 <- rw_443 %>% 
    group_by(x, y) %>% 
    group_modify(~ as.data.frame(na_interpolation(.x)),
                 option = 'stine')
   
  rw_560 <- rw_560 %>% 
    group_by(x, y) %>% 
    group_modify(~ as.data.frame(na_interpolation(.x)),
                 option = 'stine')
  

  assembly_frame <- left_join(date_frame, chla)
  
  assembly_frame <- left_join(assembly_frame, temp)
  
  assembly_frame <- left_join(assembly_frame, turb)
  
  assembly_frame <- left_join(assembly_frame, rw_443)
  
  assembly_frame <- left_join(assembly_frame, rw_560)
  
  ##
  
  filename <- paste0('cci_interpolated_test/', basename(cci_knn[ival]))
  
  write_rds(assembly_frame, filename)
  
  print(paste('Completed:', ival, 'of', length(cci_knn)))
}


kootenay <- readRDS('cci_interpolated_test/cci_kootenay.rds') %>% 
  select(x, y, date, chla_mean, turbidity_mean, lswt,
         rw_443, rw_560)

```

#5.) Import calcium data, interpolate

```{r}

### Generate North America subset CCI data

cci_lakes_shapefile <- read_sf('auxiliary_files/cci_lakes_shapefile.gpkg') %>% 
  st_transform(st_crs(4087))

na_bbox <- read_sf('auxiliary_files/north_america_bbox.gpkg') %>% 
  st_transform(st_crs(4087))

bc_bbox <- read_sf('auxiliary_files/bc_bbox.gpkg') %>% 
  st_transform(st_crs(4087))

cci_lakes_north_america <- st_intersection(cci_lakes_shapefile, na_bbox)%>% 
  select(id, name) %>% 
  mutate(area = st_area(geom))

cci_lakes_north_america$area <- as.numeric(cci_lakes_north_america$area)

cci_lakes_north_america <- cci_lakes_north_america %>% 
  mutate(area_km = area/1000000)

cci_lakes_bc <- st_intersection(cci_lakes_shapefile, bc_bbox) %>% 
  select(id, name) %>% 
  mutate(area = st_area(geom))

cci_lakes_bc$area <- as.numeric(cci_lakes_bc$area)

cci_lakes_bc <- cci_lakes_bc %>% 
  mutate(area_km = area/1000000)

### import Guerin et al 2024 data

calcium_data <- read_csv('downloads/guerin_et_al_2024_data/dryad/site-date_calcium_985955.csv') %>% 
  st_as_sf(coords = c('LONGITUDE', 'LATITUDE'),
           crs = 4326) %>% 
  st_transform(crs = 4087)

calcium_data_filtered <- calcium_data %>% 
  select(DATE, UNITS, MEAN) %>% 
  rename(date = DATE,
         units = UNITS,
         mean = MEAN) %>% 
    st_intersection(cci_lakes_north_america) %>% 
      mutate(x = sf::st_coordinates(.)[,1],
                y = sf::st_coordinates(.)[,2]) %>% 
  st_drop_geometry() %>% 
  filter(date > dmy('01-01-2002'))

###

calcium_data_filtered_bc <- calcium_data %>% 
  select(DATE, UNITS, MEAN) %>% 
  rename(date = DATE,
         units = UNITS,
         mean = MEAN) %>% 
    st_intersection(cci_lakes_bc) %>% 
      mutate(x = sf::st_coordinates(.)[,1],
                y = sf::st_coordinates(.)[,2]) %>% 
  filter(date > dmy('01-01-2016'))

### Generate list of CCI lakes with corresponding Guerin data

cci_attached <- st_join(cci_lakes_north_america, calcium_data)

calcium_matched_cci <- unique(cci_attached$name)

cci_lakes_poly_matched <- cci_lakes_north_america %>% 
  filter(name %in% calcium_matched_cci) %>% 
  select(id, name)

#write_sf(cci_lakes_poly_matched, 'auxiliary_files/cci_lakes_calcium_match.gpkg')

## Retrieve assembly frame

cci_assembly <- list.files('cci_interpolated_test/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

outer_frame <- tibble(point_id = numeric(),
                      x = numeric(),
                      y = numeric())

for (i in 1:length(cci_assembly)) {
  ival = eval(i)
  int_assembly <- read_rds(cci_assembly[ival]) %>% 
    select(x, y, point_id) %>% 
    distinct(point_id, .keep_all = TRUE)
  outer_frame <- bind_rows(outer_frame, int_assembly)
  print(paste('Completed:', ival, 'of', length(cci_assembly)))
}

outer_frame_sf <- outer_frame %>% 
  st_as_sf(coords = c('x', 'y'),
           crs = 4087) 

bc_joined_calcium <- st_join(calcium_data_filtered_bc, outer_frame_sf, 
                             join = st_nearest_feature) %>% 
  select(date, units, mean, area_km, point_id) %>% 
  st_drop_geometry() %>% 
  rowid_to_column('calcium_observation_id')

###

cci_data <- list.files('cci_interpolated_test/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE) 

cci_data_collated <- lapply(cci_data, readRDS) %>% 
  bind_rows()


cci_calcium_joined <- left_join(cci_data_collated, bc_joined_calcium,
                                by = c('point_id', 'date')) 

test_2 <- cci_calcium_joined %>% 
    mutate(calcium_index = (rw_443 - rw_560) / (rw_443 + rw_560)) %>% 
  select(x, y, date, point_id, rw_443, rw_560) %>% 
  drop_na()

test <- cci_calcium_joined %>% select(x, y, lswt, chla_mean, 
                                      turbidity_mean, rw_443, rw_560, 
                                      calcium_observation_id,
                                      units,
                                      mean,
                                      area_km) %>% 
  mutate(calcium_index = (rw_443 - rw_560) / (rw_443 + rw_560)) %>% 
  drop_na()

#write_rds(cci_calcium_joined, 'auxiliary_files/cci_calcium_joined.rds')



```

## GAM

```{r}

cci_calcium_joined <- read_rds('auxiliary_files/cci_calcium_joined.rds') %>% 
  select(x, y, date, turbidity_mean, mean, units, area_km)

```

# 6.) Suitability modeling

# 7.) Suitability composition modeling

# ~~ Supplemental

## Process continental data for calcium

```{r}

  cci_lakes_calcium_matchup_polygon <- read_sf('auxiliary_files/cci_calcium_matchup_polygon.gpkg')


  cci_slices <- list.files('cci_lakes_slices/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)
  
  test_rds <- read_rds(cci_slices[1])

  
### Updated downloads
  
path = '/home/steven/Downloads/cci_lakes_download/'

###

prefix_template <- 'https://dap.ceda.ac.uk/neodc/esacci/lakes/data/lake_products/L3S/v2.1/merged_product/'

suffix_template_a <- 'ESACCI-LAKES-L3S-LK_PRODUCTS-MERGED-'

suffix_template_b <- '-fv2.1.0.nc'

###

year_list <- c('2002', '2003', '2004', '2005', '2006', '2007', '2008', 
               '2009', '2010', '2011', '2012', '2013', '2014', '2015', 
               '2016', '2017', '2018', '2019', '2020')

month_list <- c('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')

month_daylengths <- c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)

day_list <- c( '01',  '02',  '03',  '04',  '05',  '06',  '07',  '08',  '09', 
               '10', '11', '12', '13',  '14', '15', '16', '17', '18', '19', 
               '20',  '21', '22', '23', '24', '25', '26', '27', '28', '29', 
               '30', '31')

comb_date <- paste0(year_list[1], month_list[1], day_list[1])

date_dir <- paste0(year_list[1], '/', month_list[1], '/')

options(timeout = 1000)

for (i in 4:19) {
  ival <- eval(i)
  
  interior_year <- year_list[ival]
  
  for (j in 1:12) {
    jval <- eval(j)
    
    interior_month <- month_list[jval]
    
    interior_day_length <- month_daylengths[jval]
    
    if (interior_month == '02' & interior_year == '2004') {
      interior_day_length <- 29
      print('Leap year!')
    } 
    
    if (interior_month == '02' & interior_year == '2008') {
      interior_day_length <- 29
      print('Leap year!')
    } 
    
    if (interior_month == '02' & interior_year == '2012') {
      interior_day_length <- 29
      print('Leap year!')
    } 
    
    if (interior_month == '02' & interior_year == '2016') {
      interior_day_length <- 29
      print('Leap year!')
    } 
    
    if (interior_month == '02' & interior_year == '2020') {
      interior_day_length <- 29
      print('Leap year!')
    }

    for (k in 1:interior_day_length) {
      kval <- eval(k)
      
      interior_day <- day_list[kval]
      
      comb_date <- paste0(interior_year,  interior_month, interior_day )
      
      date_dir <- paste0(interior_year, '/', interior_month , '/')
      
      filename <- paste0(prefix_template, date_dir, suffix_template_a, comb_date,
                              suffix_template_b)

      download.file(filename, paste0(path, basename(filename)))
      
      print(paste('Completed:', filename))
      
      Sys.sleep(5)
      
    }
    
  }
  
}

  
  
  

```

## Temperature data

```{r}

# Auxiliary files

cci_lakes_shapefile <- read_sf('auxiliary_files/cci_lakes_shapefile.gpkg') %>% 
  st_transform(st_crs(4087))

bc_bbox <- read_sf('auxiliary_files/bc_bbox.gpkg') %>% 
  st_transform(st_crs(4087))

cci_lakes_bc <- st_intersection(cci_lakes_shapefile, bc_bbox) %>% 
  select(id, name) %>% 
  st_transform(crs = 3005)


### EMS data

ems_lake_data <- list.files(path = 'downloads/in_situ_measurements/bc_lake_monitoring_program/lake_monitoring_raw_data/', 
                            pattern = '*.csv', 
                            full.names = TRUE) %>% 
  lapply(read_csv, col_select = c(PARAMETER, 
                                  COLLECTION_START,
                                  RESULT,
                                  UNIT,
                                  UPPER_DEPTH,
                                  LOWER_DEPTH,
                                  Level,
                                  depthsUploaded,
                                  Latitude,
                                  Longitude,
                                  WSGZTTDNM,)) %>% 
  bind_rows()

ems_lake_data <- ems_lake_data %>% mutate(id = rownames(ems_lake_data))

# Correct missing negative sign in longitude data in Shuswap Lake sites

ems_lake_data <- ems_lake_data %>% mutate(Longitude = -1*abs(Longitude))

ems_sf <- st_as_sf(ems_lake_data, 
                   coords = c('Longitude', 'Latitude'),
                   crs = 4326)

###

# Filter variables of interest

ems_vars <- ems_sf %>% filter(PARAMETER == 'Temperature-Field')

# Retrieve epilimnion results

ems_vars <- ems_vars %>% filter(Level == 'Epilimnion')

ems_vars <- ems_vars %>% 
  st_transform(crs = st_crs(3005)) %>% 
  st_intersection(cci_lakes_bc)

ems_vars <- ems_vars %>% select(PARAMETER, COLLECTION_START, RESULT)



temp_metadata <- list.files('downloads/sorensen_et_al_2024/in_situ_lake_temps/in_situ_published/final_data//', 
                            pattern = '_metadata.csv',
                            full.names = TRUE,
                            recursive = TRUE)
  
prefix_list <- c('CHA', 'CLE', 'DEV', 'FLA', 'GSL', 'HOU', 'LEW', 'MAL', 'MAR',
                 'MCC', 'MEA', 'MEN', 'MON', 'OKE', 'ONE', 'PON', 'PYR', 'RED',
                 'SAK', 'SEB', 'SEN', 'TAH', 'TAW', 'UPK', 'UTA', 'WAL', 'WAS',
                 'WIN', 'WIP')


```


# Appendices

## File moving script

```{r}


cci_files <- list.files('/mnt/023ede0b-f66f-4769-939d-421b38967538/cci_lakes_download', 
                            pattern = '*.nc',
                            full.names = TRUE,
                            recursive = TRUE)

leftover_path <- '/mnt/33ac07c2-b4a0-4614-8506-d06fb974ca86/florilegium_leftover/'

cci_rds_2 <- list.files(leftover_path, 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

cci_combined <- c(cci_rds, cci_rds_2)

###

date_frame_nc <- tibble(date = character())

for (i in 1:length(cci_files)) {
  ival <- eval(i)
  input_file <- cci_files[ival]
  input_filename <- basename(input_file)
  
  ## Extract dates from filename, check if already exists
  
  year_extract <- substr(input_filename, 37, 40)
  month_extract <- substr(input_filename, 41, 42)
  date_extract <- substr(input_filename, 43, 44)
  composite_date <- paste0(date_extract, '-', month_extract, '-', year_extract) 
  composite_date <- tibble(date = composite_date)
  date_frame <- bind_rows(date_frame, composite_date)
  print(paste('Completed:', ival, 'of', length(cci_files)))
  
}

date_frame_nc <- date_frame_nc %>% 
  rowid_to_column('date_id')


date_frame_rds <- tibble(date = character())

for (i in 1:length(cci_combined)) {
  ival <- eval(i)
  input_file <- cci_combined[ival]
  input_filename <- basename(input_file)
  
  ## Extract dates from filename, check if already exists
  
  year_extract <- substr(input_filename, 17, 20)
  month_extract <- substr(input_filename, 14, 15)
  date_extract <- substr(input_filename, 11, 12)
  composite_date <- paste0(date_extract, '-', month_extract, '-', year_extract) 
  composite_date <- tibble(date = composite_date)
  date_frame_rds <- bind_rows(date_frame_rds, composite_date)
  print(paste('Completed:', ival, 'of', length(cci_combined)))
  
}



duplicates <- date_frame_rds %>% 
  group_by(date) %>% 
  summarize(n = n()) %>% 
  filter(n == 2) %>% 
  select(date) %>% 
  rowid_to_column('duplicate_id')



for (i in 1:nrow(duplicates)) {
    ival <- eval(i)
    duplicate_interior <- duplicates %>% filter(duplicate_id == ival)
    file_interior <- str_subset(cci_combined, 
                                pattern = duplicate_interior$date)
    size_1 <- file.info(file_interior[1])
    size_2 <- file.info(file_interior[2])
    file_test <- identical(size_1$size, size_2$size)
    
    if (file_test == TRUE) {
      file.remove(file_interior[[1]])
      print(paste('Removed duplicate', ival, 'of', nrow(duplicates)))
      
    } else {
      print('Files not equal - check!')
    }
    

}


year_list <- tibble(date = character())


for (i in 1:length(cci_combined)) {
  ival <- eval(i)
  input_file <- cci_combined[ival]
  input_filename <- basename(input_file)
  
  ## Extract dates from filename, check if already exists
  
  year_extract <- substr(input_filename, 17, 20)
  
  year_extract <- tibble(date = year_extract)
  year_list <- bind_rows(year_list, year_extract)
  print(paste('Completed:', ival, 'of', length(cci_combined)))
}

year_selection <- year_list %>% distinct(date)

```

## File copying script

```{r}

cci_rds <- list.files('/run/media/steven/data_storage/cci_lakes_rds/', 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

leftover_path <- '/mnt/33ac07c2-b4a0-4614-8506-d06fb974ca86/florilegium_leftover/'

cci_rds_2 <- list.files(leftover_path, 
                            pattern = '*.rds',
                            full.names = TRUE,
                            recursive = TRUE)

cci_combined <- c(cci_rds, cci_rds_2)


year_list <- c('2002', '2003', '2004', '2005', '2006', '2007', 
               '2008', '2009', '2010', '2011', '2012', '2013', 
               '2014', '2015', '2016', '2017', '2018', '2019',
               '2020') %>% 
  as_tibble() %>% 
  rename(year = value) %>% 
  rowid_to_column('year_id')

month_list <- c('01', '02', '03', '04', '05', '06', 
                '07', '08', '09', '10', '11', '12') %>% 
  as_tibble() %>% 
  rename(month = value) %>% 
  rowid_to_column('month_id')

###

year_interior <- year_list %>% filter(year_id == 19)

year_subset <- str_subset(cci_combined, 
                          pattern = year_interior$year) %>% 
  as_tibble() %>% 
  rename(path = value) %>% 
  rowid_to_column('file_id')

newpath <- '/run/media/steven/emul_extra/cci_folder/'


for (i in 1:nrow(year_subset)) {
  ival = eval(i)
  file_interior <- year_subset %>% filter(file_id == ival)
  file_interior <- file_interior$path
  file.copy(file_interior, newpath)
  print(paste('Completed:', ival, 'of', nrow(year_subset)))
}



```

